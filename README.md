# ğŸ§  Proyecto de Machine Learning  
> Pipeline modular para un problema supervisado de clasificaciÃ³n (Churn)

---

## ğŸ“Œ DescripciÃ³n

Este proyecto implementa un pipeline completo de Machine Learning para resolver un problema supervisado tipo **clasificaciÃ³n**, desde la carga de datos hasta el despliegue del modelo.

El flujo incluye:

- Carga y validaciÃ³n de datos
- AnÃ¡lisis Exploratorio (EDA)
- Feature Engineering
- Entrenamiento de mÃºltiples modelos
- EvaluaciÃ³n comparativa
- SelecciÃ³n y guardado del mejor modelo
- Monitoreo (Data Drift)
- ExposiciÃ³n vÃ­a API
- ContenerizaciÃ³n con Docker

---

## ğŸ¯ Objetivos

âœ… Desarrollar un pipeline ML modular  
âœ… Entrenar mÃºltiples modelos y seleccionar el mejor  
âœ… Realizar monitoreo periÃ³dico  
âœ… Exponer el modelo mediante API  
âœ… Desplegar como contenedor Docker  

---

## ğŸ“‚ Estructura del Proyecto
```bash
Proyecto_Machine_Learning/
â”‚
â”œâ”€â”€ data/                              # Datos
â”‚   â”œâ”€â”€ Base_de_datos.csv              # Dataset original
â”‚   â””â”€â”€ monitoring/
â”‚       â””â”€â”€ data_drift_report.csv      # Resultados mediciÃ³n drift
â”‚
â”œâ”€â”€ mlops_pipeline/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ Cargar_datos.ipynb         # Carga inicial
â”‚       â”œâ”€â”€ compresion_eda.ipynb       # EDA completo
â”‚       â”œâ”€â”€ ft_engineering.py          # Feature Engineering
â”‚       â”œâ”€â”€ model_training.ipynb       # Entrenamiento
â”‚       â”œâ”€â”€ model_training_evaluation.py # EvaluaciÃ³n
â”‚       â”œâ”€â”€ model_evaluation.ipynb     # MÃ©tricas
â”‚       â”œâ”€â”€ model_monitoring.ipynb     # Monitoreo
â”‚       â”œâ”€â”€ model_monitoring.py        # Data drift
â”‚       â”œâ”€â”€ model_deploy.ipynb         # Despliegue
â”‚       â”œâ”€â”€ model_deploy.py            # API
â”‚       â””â”€â”€ utils/                     # MÃ³dulos auxiliares
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_model.pkl                 # Mejor modelo
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py               # UI Monitoreo
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.json
â”œâ”€â”€ set_up.bat
â””â”€â”€ README.md
```
## âœ… Funcionalidades Principales

âœ” GestiÃ³n de configuraciÃ³n mediante `config.json`  
âœ” Carga de datos centralizada  
âœ” Limpieza y validaciÃ³n automÃ¡tica  
âœ” EDA completo  
âœ” Feature Engineering programable  
âœ” Entrenamiento de mÃºltiples modelos  
âœ” EvaluaciÃ³n con mÃºltiples mÃ©tricas  
âœ” ExportaciÃ³n del mejor modelo  
âœ” Monitoreo de Data Drift  
âœ” ExposiciÃ³n de API con FastAPI  
âœ” ContenerizaciÃ³n Docker  


---

## âš™ ConfiguraciÃ³n (`config.json`)

```json
{
  "data": {
    "input_path": "data/Base_de_datos.csv",
    "target_column": "Churn",
    "test_size": 0.2,
    "random_state": 42
  },
  "model": {
    "type": "RandomForestClassifier",
    "params": {
      "n_estimators": 200,
      "max_depth": null
    }
  },
  "output": {
    "model_path": "models/best_model.pkl",
    "reports": "data/monitoring/"
  }
}
```
---

## ğŸ§° InstalaciÃ³n del entorno

âœ… **Crear entorno virtual**
python -m venv venv

âœ… Activar entorno
## Windows
venv\Scripts\activate

## MacOS / Linux
source venv/bin/activate

âœ… Instalar dependencias
pip install -r requirements.txt


---

## ğŸš€ EjecuciÃ³n del Pipeline

### ğŸ”¹ 1 â€” Carga y Limpieza
ğŸ“„ `Cargar_datos.ipynb`

Realiza:
- Lectura de dataset
- IdentificaciÃ³n de nulos
- NormalizaciÃ³n de valores
- CorrecciÃ³n de tipos de datos


### ğŸ”¹ 2 â€” AnÃ¡lisis Exploratorio (EDA)
ğŸ“„ `compresion_eda.ipynb`

Incluye:
- `describe()`
- DistribuciÃ³n de variables
- DetecciÃ³n de outliers
- Matrices de correlaciÃ³n
- RelaciÃ³n con la variable objetivo


### ğŸ”¹ 3 â€” IngenierÃ­a de CaracterÃ­sticas
ğŸ“„ `ft_engineering.py`

Incluye:
- Encoding
- Escalado
- ImputaciÃ³n
- SeparaciÃ³n Train/Test


### ğŸ”¹ 4 â€” Entrenamiento del Modelo
ğŸ“„ `model_training.ipynb`

Modelos probados:
- Logistic Regression
- RandomForest
- XGBoost
- LightGBM


### ğŸ”¹ 5 â€” EvaluaciÃ³n
ğŸ“„ `model_training_evaluation.py`

âœ” Se compara el rendimiento  
âœ” Se selecciona el mejor modelo  
âœ” Se guarda en:




### ğŸ”¹ 6 â€” Monitoreo (Data Drift)
ğŸ“„ `model_monitoring.py`

MÃ©tricas calculadas:
- KS Test
- PSI
- Jensenâ€“Shannon
- ChiÂ²

Salida:

- data/monitoring/data_drift_report.csv


---

## ğŸ“Š MÃ©tricas disponibles

- Accuracy
- Precision
- Recall
- F1-Score
- ROC-AUC
- Population Stability Index (PSI)
- Kolmogorovâ€“Smirnov (KS)
- ChiÂ²
- Jensenâ€“Shannon

---

## ğŸŒ Despliegue API

Ejecutar API localmente:

```bash
uvicorn mlops_pipeline.src.model_deploy:app --reload
```
### âœ… Endpoint disponible

/predict
Soporta:
Predicciones individuales
Predicciones por lote
Formato JSON

---
## ğŸ³ Docker

âœ… **Construir imagen**
```
docker build -t churn-model-api .
```
âœ… Ejecutar contenedor


docker run -p 8000:8000 churn-model-api
ğŸ”— Acceso por defecto

http://localhost:8000

---

## ğŸ›¡ï¸ SonarCloud â€” Calidad del CÃ³digo

Este proyecto estÃ¡ integrado con **SonarCloud** para analizar y monitorear la calidad, seguridad y mantenibilidad del cÃ³digo fuente.

ğŸ” **AnÃ¡lisis realizados:**
- âœ… Calidad del cÃ³digo (mantenibilidad)
  - Complejidad ciclomÃ¡tica
  - CÃ³digo duplicado
  - Funciones extensas o complejas
  - Code smells
- âœ… Seguridad
  - Vulnerabilidades
  - Dependencias inseguras
  - ExposiciÃ³n de datos sensibles
- âš ï¸ Cobertura de pruebas
  - (Disponible si se integran pruebas unitarias)
- âœ… Estilo e integridad
  - Nombres consistentes
  - IndentaciÃ³n adecuada
  - Buenas prÃ¡cticas generales

ğŸ”— **Dashboard del Proyecto en SonarCloud:**  
https://sonarcloud.io/project/overview?id=MiguelGalleg05_Proyecto_Machine_Learning

âœ… *El proyecto fue analizado correctamente mediante SonarCloud.  
No se detectan problemas crÃ­ticos de seguridad ni mantenibilidad.*

<img width="1919" height="968" alt="image" src="https://github.com/user-attachments/assets/1dd60c1e-00e8-4920-a93c-345dd4bc627d" />

<img width="1919" height="968" alt="image" src="https://github.com/user-attachments/assets/f405c719-f4e6-432f-be38-fa68f13bad1c" />


---

## âœ… Buenas PrÃ¡cticas

- Uso de entornos virtuales
- ModularizaciÃ³n del cÃ³digo
- Versionado con Git
- No subir modelos o datasets pesados
- ConfiguraciÃ³n centralizada (`config.json`)
- SeparaciÃ³n clara de etapas del pipeline


Este proyecto estÃ¡ bajo licencia **MIT**.

## âœ¨ Autor

**Miguel Gallego Ãlvarez**  
Machine Learning & Data Science  

ğŸ”— GitHub: https://github.com/MiguelGalleg05

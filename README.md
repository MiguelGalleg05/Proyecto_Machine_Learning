# ğŸ§  Proyecto de Machine Learning  
> Pipeline modular para un problema supervisado de clasificaciÃ³n (Churn)

---

## ğŸ“Œ DescripciÃ³n

Este proyecto implementa un pipeline completo de Machine Learning para resolver un problema supervisado tipo **clasificaciÃ³n**, desde la carga de datos hasta el despliegue del modelo.

El flujo incluye:

- Carga y validaciÃ³n de datos
- AnÃ¡lisis Exploratorio (EDA)
- Feature Engineering
- Entrenamiento de mÃºltiples modelos
- EvaluaciÃ³n comparativa
- SelecciÃ³n y guardado del mejor modelo
- Monitoreo (Data Drift)
- ExposiciÃ³n vÃ­a API
- ContenerizaciÃ³n con Docker

---

## ğŸ¯ Objetivos

âœ… Desarrollar un pipeline ML modular  
âœ… Entrenar mÃºltiples modelos y seleccionar el mejor  
âœ… Realizar monitoreo periÃ³dico  
âœ… Exponer el modelo mediante API  
âœ… Desplegar como contenedor Docker  

---

## ğŸ“‚ Estructura del Proyecto
```bash
Proyecto_Machine_Learning/
â”‚
â”œâ”€â”€ data/                              # Datos
â”‚   â”œâ”€â”€ Base_de_datos.csv              # Dataset original
â”‚   â””â”€â”€ monitoring/
â”‚       â””â”€â”€ data_drift_report.csv      # Resultados mediciÃ³n drift
â”‚
â”œâ”€â”€ mlops_pipeline/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ Cargar_datos.ipynb         # Carga inicial
â”‚       â”œâ”€â”€ compresion_eda.ipynb       # EDA completo
â”‚       â”œâ”€â”€ ft_engineering.py          # Feature Engineering
â”‚       â”œâ”€â”€ model_training.ipynb       # Entrenamiento
â”‚       â”œâ”€â”€ model_training_evaluation.py # EvaluaciÃ³n
â”‚       â”œâ”€â”€ model_evaluation.ipynb     # MÃ©tricas
â”‚       â”œâ”€â”€ model_monitoring.ipynb     # Monitoreo
â”‚       â”œâ”€â”€ model_monitoring.py        # Data drift
â”‚       â”œâ”€â”€ model_deploy.ipynb         # Despliegue
â”‚       â”œâ”€â”€ model_deploy.py            # API
â”‚       â””â”€â”€ utils/                     # MÃ³dulos auxiliares
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_model.pkl                 # Mejor modelo
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py               # UI Monitoreo
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.json
â”œâ”€â”€ set_up.bat
â””â”€â”€ README.md
```
## âœ… Funcionalidades Principales

âœ” GestiÃ³n de configuraciÃ³n mediante `config.json`  
âœ” Carga de datos centralizada  
âœ” Limpieza y validaciÃ³n automÃ¡tica  
âœ” EDA completo  
âœ” Feature Engineering programable  
âœ” Entrenamiento de mÃºltiples modelos  
âœ” EvaluaciÃ³n con mÃºltiples mÃ©tricas  
âœ” ExportaciÃ³n del mejor modelo  
âœ” Monitoreo de Data Drift  
âœ” ExposiciÃ³n de API con FastAPI  
âœ” ContenerizaciÃ³n Docker  


---

## âš™ ConfiguraciÃ³n (`config.json`)

```json
{
  "data": {
    "input_path": "data/Base_de_datos.csv",
    "target_column": "Churn",
    "test_size": 0.2,
    "random_state": 42
  },
  "model": {
    "type": "RandomForestClassifier",
    "params": {
      "n_estimators": 200,
      "max_depth": null
    }
  },
  "output": {
    "model_path": "models/best_model.pkl",
    "reports": "data/monitoring/"
  }
}
```
---

## ğŸ§° InstalaciÃ³n del entorno

âœ… **Crear entorno virtual**
python -m venv venv

âœ… Activar entorno
## Windows
venv\Scripts\activate

## MacOS / Linux
source venv/bin/activate

âœ… Instalar dependencias
pip install -r requirements.txt


---

## ğŸš€ EjecuciÃ³n del Pipeline

### ğŸ”¹ 1 â€” Carga y Limpieza
ğŸ“„ `Cargar_datos.ipynb`

Realiza:
- Lectura de dataset
- IdentificaciÃ³n de nulos
- NormalizaciÃ³n de valores
- CorrecciÃ³n de tipos de datos


### ğŸ”¹ 2 â€” AnÃ¡lisis Exploratorio (EDA)
ğŸ“„ `compresion_eda.ipynb`

Incluye:
- `describe()`
- DistribuciÃ³n de variables
- DetecciÃ³n de outliers
- Matrices de correlaciÃ³n
- RelaciÃ³n con la variable objetivo


### ğŸ”¹ 3 â€” IngenierÃ­a de CaracterÃ­sticas
ğŸ“„ `ft_engineering.py`

Incluye:
- Encoding
- Escalado
- ImputaciÃ³n
- SeparaciÃ³n Train/Test


### ğŸ”¹ 4 â€” Entrenamiento del Modelo
ğŸ“„ `model_training.ipynb`

Modelos probados:
- Logistic Regression
- RandomForest
- XGBoost
- LightGBM


### ğŸ”¹ 5 â€” EvaluaciÃ³n
ğŸ“„ `model_training_evaluation.py`

âœ” Se compara el rendimiento  
âœ” Se selecciona el mejor modelo  
âœ” Se guarda en:




### ğŸ”¹ 6 â€” Monitoreo (Data Drift)
ğŸ“„ `model_monitoring.py`

MÃ©tricas calculadas:
- KS Test
- PSI
- Jensenâ€“Shannon
- ChiÂ²

Salida:

- data/monitoring/data_drift_report.csv


---

## ğŸ“Š MÃ©tricas disponibles

- Accuracy
- Precision
- Recall
- F1-Score
- ROC-AUC
- Population Stability Index (PSI)
- Kolmogorovâ€“Smirnov (KS)
- ChiÂ²
- Jensenâ€“Shannon

---

## ğŸŒ Despliegue API

Ejecutar API localmente:

```bash
uvicorn mlops_pipeline.src.model_deploy:app --reload
```
### âœ… Endpoint disponible

/predict
Soporta:
Predicciones individuales
Predicciones por lote
Formato JSON

---
## ğŸ³ Docker

âœ… **Construir imagen**
```
docker build -t churn-model-api .
```
âœ… Ejecutar contenedor


docker run -p 8000:8000 churn-model-api
ğŸ”— Acceso por defecto

http://localhost:8000

---

## ğŸ›¡ï¸ SonarCloud â€” Calidad del CÃ³digo

Este proyecto estÃ¡ integrado con **SonarCloud** para analizar y monitorear la calidad, seguridad y mantenibilidad del cÃ³digo fuente.

ğŸ” **AnÃ¡lisis realizados:**
- âœ… Calidad del cÃ³digo (mantenibilidad)
  - Complejidad ciclomÃ¡tica
  - CÃ³digo duplicado
  - Funciones extensas o complejas
  - Code smells
- âœ… Seguridad
  - Vulnerabilidades
  - Dependencias inseguras
  - ExposiciÃ³n de datos sensibles
- âš ï¸ Cobertura de pruebas
  - (Disponible si se integran pruebas unitarias)
- âœ… Estilo e integridad
  - Nombres consistentes
  - IndentaciÃ³n adecuada
  - Buenas prÃ¡cticas generales

ğŸ”— **Dashboard del Proyecto en SonarCloud:**  
https://sonarcloud.io/project/overview?id=MiguelGalleg05_Proyecto_Machine_Learning

âœ… *El proyecto fue analizado correctamente mediante SonarCloud.  
No se detectan problemas crÃ­ticos de seguridad ni mantenibilidad.*

<img width="1919" height="968" alt="image" src="https://github.com/user-attachments/assets/1dd60c1e-00e8-4920-a93c-345dd4bc627d" />

<img width="1919" height="968" alt="image" src="https://github.com/user-attachments/assets/f405c719-f4e6-432f-be38-fa68f13bad1c" />


---

## ğŸ§© Decisiones de Feature Engineering

Durante el proceso de ingenierÃ­a de caracterÃ­sticas se tomaron decisiones clave para garantizar
que los datos estuvieran en un formato Ã³ptimo para el modelado:

### ğŸ”¹ Limpieza y consistencia
- Se unificaron valores nulos y se imputaron segÃºn el tipo de variable.
- Se identificaron valores inconsistentes o categorizaciones redundantes.

### ğŸ”¹ CodificaciÃ³n (Encoding)
- Variables categÃ³ricas nominales â†’ One-Hot Encoding.
- Variables binarias â†’ Label Encoding.
> DecisiÃ³n: One-Hot permitiÃ³ evitar relaciones ordinales inexistentes y mejorar el rendimiento de modelos lineales.

### ğŸ”¹ Escalamiento
- Se aplicÃ³ StandardScaler a variables numÃ©ricas continuas.
> JustificaciÃ³n: facilita convergencia y estabiliza modelos lineales y basados en distancia.

### ğŸ”¹ SelecciÃ³n de variables
- Se eliminaron columnas irrelevantes (ej. identificadores).
- Se evaluÃ³ correlaciÃ³n y gain-importance para descartar atributos sin valor predictivo.

### ğŸ”¹ GeneraciÃ³n de nuevas caracterÃ­sticas
- Se analizaron relaciones entre atributos para proponer combinaciones Ãºtiles.
> Se documentaron candidatos, aunque no todos aportaron mejora significativa.

> âœ… Estas decisiones mejoraron la estabilidad del entrenamiento, reduciendo ruido y manteniendo informaciÃ³n relevante.


---

## ğŸ“Š EvaluaciÃ³n y MÃ©tricas del Modelo

Durante la fase de entrenamiento se evaluaron varios algoritmos:

- Logistic Regression  
- Random Forest  
- XGBoost  
- LightGBM  

Se compararon usando:
- Accuracy
- Precision
- Recall
- F1-Score
- ROC-AUC

> El modelo seleccionado fue **Random Forest**, debido a balance entre desempeÃ±o, estabilidad y bajo riesgo de sobreajuste.

### ğŸ”¹ Reportes visuales

Se generaron las siguientes visualizaciones para justificar la selecciÃ³n:

- âœ… ROC Curves comparativas
- âœ… Matriz de confusiÃ³n
- âœ… Feature importance
- âœ… Learning curves

> Estas grÃ¡ficas mostraron que el modelo final mantenÃ­a buen balance entre sensibilidad y precisiÃ³n,
adecuado para el caso de churn donde ambas son relevantes.


---

## ğŸ“ˆ ExtensiÃ³n del Monitoreo

La app de monitoreo fue ampliada para incluir:

### ğŸ”¹ Comparativas de distribuciÃ³n
- Se graficÃ³ la diferencia entre distribuciÃ³n histÃ³rica vs actual para cada variable.
- Se resaltaron variables con desviaciones estadÃ­sticamente significativas.

### ğŸ”¹ MÃ©tricas de Drift
Se calcularon:
- PSI (Population Stability Index)
- KS Test
- Jensen-Shannon Distance
- Chi-Square para categÃ³ricas

> La combinaciÃ³n de estas mÃ©tricas permite detectar cambios tanto en forma como en proporciones de la data.

### ğŸ”¹ Alertas visuales
ImplementaciÃ³n tipo â€œsemÃ¡foroâ€:
- ğŸŸ¢ Estable
- ğŸŸ¡ AtenciÃ³n
- ğŸ”´ CrÃ­tico

> Umbrales configurables permiten identificar cuÃ¡ndo reentrenar el modelo.

### ğŸ”¹ GeneraciÃ³n de reportes
- ExportaciÃ³n periÃ³dica en `.csv` â†’ `data/monitoring/`
- Resumen con variables afectadas

> Estas capacidades permiten monitoreo continuo y facilitan diagnÃ³sticos para mantenimiento del modelo.
### En el archivo model_training.ipynb se habla de esto y los resultados.

---


## âœ… Buenas PrÃ¡cticas

- Uso de entornos virtuales
- ModularizaciÃ³n del cÃ³digo
- Versionado con Git
- No subir modelos o datasets pesados
- ConfiguraciÃ³n centralizada (`config.json`)
- SeparaciÃ³n clara de etapas del pipeline


Este proyecto estÃ¡ bajo licencia **MIT**.

## âœ¨ Autor

**Miguel Gallego Ãlvarez**  
Machine Learning & Data Science  

ğŸ”— GitHub: https://github.com/MiguelGalleg05
